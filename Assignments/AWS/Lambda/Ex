----------------------------------------------------------------------------
1 - cost optimization using Lambda function. 
----------------------------------------------------------------------------
1. create 1 ec2  with any configuration
    Name - cost-ec2
    Volume - 8gb 

2. create a snapshot from the volume of the instance cost-ec2 
    Name - snap1

3. create a additional volume (new-ebs) and create a snapshot from it as 
    EBS name -  new-ebs  
    snap Name - snap2

4. create a lambda function in which pasted the below code to delete the  stale resource (snapshots).
      name - lab2 
    Code: .py 
import boto3
def lambda_handler(event, context):
    ec2 = boto3.client('ec2')
    # Get all EBS snapshots
    response = ec2.describe_snapshots(OwnerIds=['self'])
    # Get all active EC2 instance IDs
    instances_response = ec2.describe_instances(Filters=[{'Name':
'instance-state-name', 'Values': ['running']}])
    active_instance_ids = set()
    for reservation in instances_response['Reservations']:
        for instance in reservation['Instances']:
            active_instance_ids.add(instance['InstanceId'])
# Iterate through each snapshot and delete if it's not attached to any volume or the volume is not attached to a running instance
    for snapshot in response['Snapshots']:
        snapshot_id = snapshot['SnapshotId']
        volume_id = snapshot.get('VolumeId')
        if not volume_id:
            # Delete the snapshot if it's not attached to any volume
            ec2.delete_snapshot(SnapshotId=snapshot_id)
            print(f"Deleted EBS snapshot {snapshot_id} as it was not attached to any volume.")
        else:
            # Check if the volume still exists
            try:
                volume_response = ec2.describe_volumes(VolumeIds=[volume_id])
                if not volume_response['Volumes'][0]['Attachments']:
                    ec2.delete_snapshot(SnapshotId=snapshot_id)
                    print(f"Deleted EBS snapshot {snapshot_id} as it was taken from a volume not attached to any running instance.")
            except ec2.exceptions.ClientError as e:
                if e.response['Error']['Code'] == 'InvalidVolume.NotFound':
# The volume associated with the snapshot is not found (it might have been deleted)
                      ec2.delete_snapshot(SnapshotId=snapshot_id)
                      print(f"Deleted EBS snapshot {snapshot_id} as its associated volume was not found.")

5 . Deleted the Ec2 instance, ran the lambda function again and verified if it deletes the snapshot whose ebs volume is not found as the ec2 was deleted.


--------------------------------------------------------------------------------------------------------------------------------------------------------
2. Event Driven function trigger by S3 bucket.
--------------------------------------------------------------------------------------------------------------------------------------------------------

1. Create an Amazon S3 bucket.
Region - ohio 
Bucket type,General purpose 

2.Create a policy 

name -  s3-trigger-tutorial
JSON CODE:
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "logs:PutLogEvents",
                "logs:CreateLogGroup",
                "logs:CreateLogStream"
            ],
            "Resource": "arn:aws:logs:*:*:*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject"
            ],
            "Resource": "arn:aws:s3:::*/*"
        }
    ]
}

3.Craete Role and attach the policy.
policy search box -  s3-trigger-tutorial. click Next.
Role details - Role name - lambda-s3-trigger-role,  click  Create role.

4. Create a Lambda function that returns the object type of objects in an Amazon S3 bucket.
Click  Create function -  Author from scratch
    Under Basic information, do the following:
        Function name -  s3-trigger-tutorial
        Runtime -  Python 3.13.
        Architecture - x86_64.
        Change default execution role tab -  choose Use an existing role - lambda-s3-trigger-role - Click Create function.

5. Configure a Lambda trigger that invokes your function when objects are uploaded to your bucket.

a. In the Code source pane on the Lambda console, paste the code into the code editor, replacing the code that Lambda created.

# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0
import json
import urllib.parse
import boto3

print('Loading function')

s3 = boto3.client('s3')


def lambda_handler(event, context):
    #print("Received event: " + json.dumps(event, indent=2))

    # Get the object from the event and show its content type
    bucket = event['Records'][0]['s3']['bucket']['name']
    key = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'], encoding='utf-8')
    try:
        response = s3.get_object(Bucket=bucket, Key=key)
        print("CONTENT TYPE: " + response['ContentType'])
        return response['ContentType']
    except Exception as e:
        print(e)
        print('Error getting object {} from bucket {}. Make sure they exist and your bucket is in the same region as this function.'.format(key, bucket))
        raise e
              

 b. click  Deploy to update function code.

6. create the trigger for the function .
 choose S3.

Under Bucket - select bucket name 
Under Event types - select - only PUT
Under Recursive invocation, select the check box to acknowledge 
Choose Add.

7. Test your function, using the trigger.
upload a image or file in the s3 bucket and check for the logs under cloudwatch for lambda function  -  /aws/lambda/s3-trigger-tutorial
if runtime error  go to lambda function -> under configurations tab - edit the timeout to 10 secs and save 



--------------------------------------------------------------------------------------------------------------------------------------------------------










--------------------------------------------------------------------------------------------------------------------------------------------------------
